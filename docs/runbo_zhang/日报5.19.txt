2025-05-19 日报 张润博
1.git提交（已完成）
2.oracle实践（已完成）
3.简历（进行中）
上传地址:https://github.com/113RbZhang/bj_i18_teams.git
分支:dev_runbo_zhang






简历：
基于 Flink 的电商评论敏感词筛选项目
项目描述：
本项目聚焦于电商平台海量用户评论数据的敏感词检测与分级处理，旨在通过实时与准实时分析，快速识别评论中的敏感信息，维护平台内容安全。项目中，电商用户评论数据经由 Kafka 消息队列源源不断流入系统，基于 Java 语言，运用 Flink 框架对数据进行实时流式处理。
敏感词库存储于 Redis，通过读取 Redis 中的敏感词库，对评论数据进行 P0 级敏感词检测，快速识别出严重违规的敏感词汇。对于 P1 级敏感词检测，借助 .SensitiveWordHelper 工具，实现对相对隐晦、潜在敏感内容的深度挖掘。经 Flink 处理后的结果数据，存储至Kafka方便其他部门进行及时处理，并将数据映射到 Doris 数据仓库，方便后续通过 FineBI 进行可视化分析，生成敏感词分布、趋势等报表，辅助运营人员掌握平台内容安全状况。
开发环境：
IDEA + Java + Shell + JDK 1.8
技术架构：
Kafka + Flink +  Redis + Doris + FineBI
责任描述：
主导项目技术方案设计，完成 Flink 作业架构搭建，实现从 Kafka 消费评论数据、调用 Redis 敏感词库及 SensitiveWordHelper 工具进行分级检测，到数据存储与同步全链路开发。
负责使用自定义分词器将评论数据处理。
负责 Redis 敏感词库的设计与维护，制定 P0 和 P1 敏感词分级规则，优化敏感词检索效率。
对 HBase 和 Doris 的数据存储结构进行设计与调优，确保数据高效存储与查询，满足 FineBI 可视化分析需求。
运用 Shell 脚本编写自动化部署与监控脚本，实现项目的一键部署与运行状态实时监控，保障项目稳定运行。
技术要点：
Flink 流式处理：利用 Flink 的窗口计算、状态管理等特性，实现对电商评论数据的实时高效处理，在敏感词判断之前使用自定义分词器将评论数据进行初步处理，并写入 Kafka 确保敏感词检测低延迟、高吞吐。
Redis 集成：通过 Jedis 客户端与 Redis 进行交互，采用批量查询、缓存预热等策略，提升敏感词检索性能，减少 Redis 访问压力。

